{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "866557a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from data_loader import DataLoader\n",
    "from models import MODELS\n",
    "from misc.evaluation_metrics import *\n",
    "from attacks import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66a8d70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>frequency</th>\n",
       "      <th>description</th>\n",
       "      <th>source</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Electricity Transformer Data - 15 min</td>\n",
       "      <td>fifteen minutes</td>\n",
       "      <td>...</td>\n",
       "      <td>https://github.com/zhouhaoyi/ETDataset</td>\n",
       "      <td>data/electricity_transformer_15min.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Metro Interstate Human Traffic Volume</td>\n",
       "      <td>hour</td>\n",
       "      <td>Hourly Interstate 94 Westbound traffic volume ...</td>\n",
       "      <td>https://archive.ics.uci.edu/ml/datasets/Metro+...</td>\n",
       "      <td>data/Metro_Interstate_Traffic_Volume.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beijing-Guanyuan Air-Quality</td>\n",
       "      <td>hour</td>\n",
       "      <td>This hourly data set considers 6 main air poll...</td>\n",
       "      <td>https://archive.ics.uci.edu/ml/datasets/Beijin...</td>\n",
       "      <td>data/beijing_air_quality_Data_Guanyuan_2013030...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Solar Generation - EnerjiSA</td>\n",
       "      <td>hour</td>\n",
       "      <td>Solar generation data of unlicenced solar cen...</td>\n",
       "      <td>https://www.kaggle.com/competitions/enerjisa-e...</td>\n",
       "      <td>data/enerjisa_solar_generation.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    name        frequency  \\\n",
       "0  Electricity Transformer Data - 15 min  fifteen minutes   \n",
       "1  Metro Interstate Human Traffic Volume             hour   \n",
       "2           Beijing-Guanyuan Air-Quality             hour   \n",
       "3            Solar Generation - EnerjiSA             hour   \n",
       "\n",
       "                                         description  \\\n",
       "0                                                ...   \n",
       "1  Hourly Interstate 94 Westbound traffic volume ...   \n",
       "2  This hourly data set considers 6 main air poll...   \n",
       "3   Solar generation data of unlicenced solar cen...   \n",
       "\n",
       "                                              source  \\\n",
       "0             https://github.com/zhouhaoyi/ETDataset   \n",
       "1  https://archive.ics.uci.edu/ml/datasets/Metro+...   \n",
       "2  https://archive.ics.uci.edu/ml/datasets/Beijin...   \n",
       "3  https://www.kaggle.com/competitions/enerjisa-e...   \n",
       "\n",
       "                                                path  \n",
       "0             data/electricity_transformer_15min.csv  \n",
       "1           data/Metro_Interstate_Traffic_Volume.csv  \n",
       "2  data/beijing_air_quality_Data_Guanyuan_2013030...  \n",
       "3                 data/enerjisa_solar_generation.csv  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dl = DataLoader()\n",
    "info = dl.get_info()\n",
    "\n",
    "display(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "323d0ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        value\n",
      "DateTime                     \n",
      "2019-01-01 00:00:00  0.000000\n",
      "2019-01-01 01:00:00  0.000000\n",
      "2019-01-01 02:00:00  0.000008\n",
      "2019-01-01 03:00:00  0.000000\n",
      "2019-01-01 04:00:00  0.000008\n",
      "...                       ...\n",
      "2021-11-30 19:00:00  0.000000\n",
      "2021-11-30 20:00:00  0.000000\n",
      "2021-11-30 21:00:00  0.000000\n",
      "2021-11-30 22:00:00  0.000000\n",
      "2021-11-30 23:00:00  0.000000\n",
      "\n",
      "[25560 rows x 1 columns]\n",
      "                            value\n",
      "DateTime                         \n",
      "2019-01-01 00:00:00  0.000000e+00\n",
      "2019-01-01 01:00:00  0.000000e+00\n",
      "2019-01-01 02:00:00  1.753158e-08\n",
      "2019-01-01 03:00:00  0.000000e+00\n",
      "2019-01-01 04:00:00  1.753158e-08\n",
      "...                           ...\n",
      "2021-11-30 19:00:00  0.000000e+00\n",
      "2021-11-30 20:00:00  0.000000e+00\n",
      "2021-11-30 21:00:00  0.000000e+00\n",
      "2021-11-30 22:00:00  0.000000e+00\n",
      "2021-11-30 23:00:00  0.000000e+00\n",
      "\n",
      "[25560 rows x 1 columns]\n",
      "Solar Generation - EnerjiSA\n",
      "(17826, 92, 1)\n",
      "(7641, 92, 1)\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 32)                4352      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,385\n",
      "Trainable params: 4,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 00:44:02.491795: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-16 00:44:02.506329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-16 00:44:02.506643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-16 00:44:02.507215: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-16 00:44:02.508386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-16 00:44:02.508548: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-16 00:44:02.508697: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-16 00:44:02.829257: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-16 00:44:02.829427: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-16 00:44:02.829564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-16 00:44:02.829687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1 MB memory:  -> device: 0, name: NVIDIA GeForce GTX TITAN X, pci bus id: 0000:0b:00.0, compute capability: 5.2\n",
      "2022-12-16 00:44:02.841547: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 1.12M (1179648 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-12-16 00:44:02.850815: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 1.01M (1061888 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-12-16 00:44:12.985804: W tensorflow/core/common_runtime/bfc_allocator.cc:462] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.26MiB (rounded to 6560000)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-12-16 00:44:12.985832: I tensorflow/core/common_runtime/bfc_allocator.cc:1010] BFCAllocator dump for GPU_0_bfc\n",
      "2022-12-16 00:44:12.985844: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (256): \tTotal Chunks: 16, Chunks in use: 16. 4.0KiB allocated for chunks. 4.0KiB in use in bin. 196B client-requested in use in bin.\n",
      "2022-12-16 00:44:12.985853: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (512): \tTotal Chunks: 2, Chunks in use: 2. 1.0KiB allocated for chunks. 1.0KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2022-12-16 00:44:12.985860: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2022-12-16 00:44:12.985867: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-16 00:44:12.985874: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-16 00:44:12.985880: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-16 00:44:12.985889: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16384): \tTotal Chunks: 1, Chunks in use: 1. 16.0KiB allocated for chunks. 16.0KiB in use in bin. 16.0KiB client-requested in use in bin.\n",
      "2022-12-16 00:44:12.985896: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (32768): \tTotal Chunks: 1, Chunks in use: 0. 45.5KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-16 00:44:12.985902: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-16 00:44:12.985908: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-16 00:44:12.985914: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-16 00:44:12.985921: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (524288): \tTotal Chunks: 1, Chunks in use: 0. 865.8KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-16 00:44:12.985928: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-16 00:44:12.985934: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-16 00:44:12.985940: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-16 00:44:12.985946: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-16 00:44:12.985952: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-16 00:44:12.985959: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-16 00:44:12.985965: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-16 00:44:12.985974: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-16 00:44:12.985980: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-16 00:44:12.985987: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] Bin for 6.26MiB was 4.00MiB, Chunk State: \n",
      "2022-12-16 00:44:12.985992: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 955904\n",
      "2022-12-16 00:44:12.986002: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b069a0000 of size 256 next 1\n",
      "2022-12-16 00:44:12.986007: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b069a0100 of size 1280 next 2\n",
      "2022-12-16 00:44:12.986013: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b069a0600 of size 256 next 3\n",
      "2022-12-16 00:44:12.986018: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b069a0700 of size 256 next 4\n",
      "2022-12-16 00:44:12.986023: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b069a0800 of size 256 next 5\n",
      "2022-12-16 00:44:12.986028: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b069a0900 of size 256 next 6\n",
      "2022-12-16 00:44:12.986033: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b069a0a00 of size 256 next 12\n",
      "2022-12-16 00:44:12.986038: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b069a0b00 of size 256 next 9\n",
      "2022-12-16 00:44:12.986043: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b069a0c00 of size 256 next 7\n",
      "2022-12-16 00:44:12.986049: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b069a0d00 of size 512 next 8\n",
      "2022-12-16 00:44:12.986054: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b069a0f00 of size 256 next 10\n",
      "2022-12-16 00:44:12.986059: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b069a1000 of size 256 next 13\n",
      "2022-12-16 00:44:12.986064: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b069a1100 of size 512 next 15\n",
      "2022-12-16 00:44:12.986069: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b069a1300 of size 256 next 16\n",
      "2022-12-16 00:44:12.986074: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b069a1400 of size 256 next 17\n",
      "2022-12-16 00:44:12.986079: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b069a1500 of size 256 next 18\n",
      "2022-12-16 00:44:12.986084: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b069a1600 of size 256 next 19\n",
      "2022-12-16 00:44:12.986089: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b069a1700 of size 256 next 20\n",
      "2022-12-16 00:44:12.986094: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b069a1800 of size 256 next 21\n",
      "2022-12-16 00:44:12.986099: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at b069a1900 of size 46592 next 11\n",
      "2022-12-16 00:44:12.986104: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b069acf00 of size 16384 next 14\n",
      "2022-12-16 00:44:12.986110: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at b069b0f00 of size 886528 next 18446744073709551615\n",
      "2022-12-16 00:44:12.986114: I tensorflow/core/common_runtime/bfc_allocator.cc:1071]      Summary of in-use Chunks by size: \n",
      "2022-12-16 00:44:12.986121: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 16 Chunks of size 256 totalling 4.0KiB\n",
      "2022-12-16 00:44:12.986128: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 512 totalling 1.0KiB\n",
      "2022-12-16 00:44:12.986133: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2022-12-16 00:44:12.986140: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 16384 totalling 16.0KiB\n",
      "2022-12-16 00:44:12.986146: I tensorflow/core/common_runtime/bfc_allocator.cc:1078] Sum Total of in-use chunks: 22.2KiB\n",
      "2022-12-16 00:44:12.986151: I tensorflow/core/common_runtime/bfc_allocator.cc:1080] total_region_allocated_bytes_: 955904 memory_limit_: 1179648 available bytes: 223744 curr_region_allocation_bytes_: 2359296\n",
      "2022-12-16 00:44:12.986160: I tensorflow/core/common_runtime/bfc_allocator.cc:1086] Stats: \n",
      "Limit:                         1179648\n",
      "InUse:                           22784\n",
      "MaxInUse:                        69120\n",
      "NumAllocs:                          38\n",
      "MaxAllocSize:                    28672\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-12-16 00:44:12.986167: W tensorflow/core/common_runtime/bfc_allocator.cc:474] *____***____________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# train LSTM model\u001b[39;00m\n\u001b[1;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m,loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMSE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python_envs/cmpe/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/python_envs/cmpe/lib/python3.10/site-packages/keras/engine/training.py:1334\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1328\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cluster_coordinator \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mcoordinator\u001b[38;5;241m.\u001b[39mClusterCoordinator(\n\u001b[1;32m   1329\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy)\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy\u001b[38;5;241m.\u001b[39mscope(), \\\n\u001b[1;32m   1332\u001b[0m      training_utils\u001b[38;5;241m.\u001b[39mRespectCompiledTrainableState(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1333\u001b[0m   \u001b[38;5;66;03m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[39;00m\n\u001b[0;32m-> 1334\u001b[0m   data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1335\u001b[0m \u001b[43m      \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m      \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[43m      \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1338\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1340\u001b[0m \u001b[43m      \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1341\u001b[0m \u001b[43m      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1342\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[43m      \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1345\u001b[0m \u001b[43m      \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1346\u001b[0m \u001b[43m      \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1347\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1348\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1350\u001b[0m   \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   1351\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m~/python_envs/cmpe/lib/python3.10/site-packages/keras/engine/data_adapter.py:1399\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cluster_coordinator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1398\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1399\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python_envs/cmpe/lib/python3.10/site-packages/keras/engine/data_adapter.py:1149\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1146\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution \u001b[38;5;241m=\u001b[39m steps_per_execution\n\u001b[1;32m   1148\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1163\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/python_envs/cmpe/lib/python3.10/site-packages/keras/engine/data_adapter.py:236\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    226\u001b[0m              x,\n\u001b[1;32m    227\u001b[0m              y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m              shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    234\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    235\u001b[0m   \u001b[38;5;28msuper\u001b[39m(TensorLikeDataAdapter, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(x, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 236\u001b[0m   x, y, sample_weights \u001b[38;5;241m=\u001b[39m \u001b[43m_process_tensorlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m   sample_weight_modes \u001b[38;5;241m=\u001b[39m broadcast_sample_weight_modes(\n\u001b[1;32m    238\u001b[0m       sample_weights, sample_weight_modes)\n\u001b[1;32m    240\u001b[0m   \u001b[38;5;66;03m# If sample_weights are not specified for an output use 1.0 as weights.\u001b[39;00m\n",
      "File \u001b[0;32m~/python_envs/cmpe/lib/python3.10/site-packages/keras/engine/data_adapter.py:1043\u001b[0m, in \u001b[0;36m_process_tensorlike\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _scipy_sparse_to_sparse_tensor(x)\n\u001b[1;32m   1041\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m-> 1043\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_convert_single_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mlist_to_tuple(inputs)\n",
      "File \u001b[0;32m~/python_envs/cmpe/lib/python3.10/site-packages/tensorflow/python/util/nest.py:914\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    910\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    911\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    915\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/python_envs/cmpe/lib/python3.10/site-packages/tensorflow/python/util/nest.py:914\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    910\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    911\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    915\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/python_envs/cmpe/lib/python3.10/site-packages/keras/engine/data_adapter.py:1038\u001b[0m, in \u001b[0;36m_process_tensorlike.<locals>._convert_single_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, np\u001b[38;5;241m.\u001b[39mfloating):\n\u001b[1;32m   1037\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mfloatx()\n\u001b[0;32m-> 1038\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_scipy_sparse(x):\n\u001b[1;32m   1040\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _scipy_sparse_to_sparse_tensor(x)\n",
      "File \u001b[0;32m~/python_envs/cmpe/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/python_envs/cmpe/lib/python3.10/site-packages/tensorflow/python/framework/errors_impl.py:461\u001b[0m, in \u001b[0;36mInternalError.__init__\u001b[0;34m(self, node_def, op, message, *args)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrors.InternalError\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mInternalError\u001b[39;00m(OpError):\n\u001b[1;32m    453\u001b[0m   \u001b[38;5;124;03m\"\"\"Raised when the system experiences an internal error.\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \n\u001b[1;32m    455\u001b[0m \u001b[38;5;124;03m  This exception is raised when some invariant expected by the runtime\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;124;03m  @@__init__\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, node_def, op, message, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;124;03m\"\"\"Creates an `InternalError`.\"\"\"\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28msuper\u001b[39m(InternalError, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(node_def, op, message, INTERNAL, \u001b[38;5;241m*\u001b[39margs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = dl.load(3)\n",
    "(X_train, y_train, X_test, y_test), scaler = dl.prepare_dataset(23*4,1)\n",
    "\n",
    "print(dl.last_loaded_info[\"name\"])\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print()\n",
    "\n",
    "# model = MODELS[-1]((X_train.shape[1],X_train.shape[2]), 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32,activation=\"tanh\", input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(1))\n",
    "model.summary()\n",
    "model.compile(optimizer=\"adam\",loss=\"MSE\")\n",
    "\n",
    "# train LSTM model\n",
    "model.compile(optimizer=\"adam\",loss=\"MSE\")\n",
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad764b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred = scaler.inverse_transform(pred).reshape(1,-1)[0]\n",
    "y_test_inv = scaler.inverse_transform(y_test).reshape(1,-1)[0]\n",
    "\n",
    "\n",
    "def SMAPE(true, pred):\n",
    "    return np.mean((abs(true - pred) / ((abs(true) + abs(pred))/2))*100)\n",
    "\n",
    "def MDAPE(true, pred):\n",
    "    return np.median((abs(true - pred) / true)*100)\n",
    "\n",
    "\n",
    "print(\"MAE :\", np.mean(abs(y_test_inv - pred)))\n",
    "print(\"RMSE :\", RMSE(y_test_inv,pred))\n",
    "print(\"MSE :\", MSE(y_test_inv,pred))\n",
    "print(\"MAPE :\", MAPE(y_test_inv,pred))\n",
    "print(\"SMAPE :\", SMAPE(y_test_inv,pred))\n",
    "print(\"MDAPE :\", MDAPE(y_test_inv,pred))\n",
    "print(\"R2 :\", r2_score(y_test_inv,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0723fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(go.Line(y = y_test_inv, name=\"original\"))\n",
    "fig.add_trace(go.Line(y = pred, name=\"predicted\"))\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeae3f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d006f87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1dad72be",
   "metadata": {},
   "source": [
    "# Adversarial Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb76ef5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_adversarial_fgsm = fgsm_attack(X_test, y_test, model, 0.01, np.inf, clip_min = 0, clip_max = 100)\n",
    "\n",
    "pred = model.predict(X_adversarial_fgsm)\n",
    "pred = scaler.inverse_transform(pred).reshape(1,-1)[0]\n",
    "y_test_inv = scaler.inverse_transform(y_test).reshape(1,-1)[0]\n",
    "\n",
    "print(\"MAE :\", np.mean(abs(y_test_inv - pred)))\n",
    "print(\"RMSE :\", RMSE(y_test_inv,pred))\n",
    "print(\"MSE :\", MSE(y_test_inv,pred))\n",
    "print(\"MAPE :\", MAPE(y_test_inv[y_test_inv >= 10],pred[y_test_inv >= 10]))\n",
    "print(\"SMAPE :\", SMAPE(y_test_inv,pred))\n",
    "print(\"R2 :\", r2_score(y_test_inv,pred))\n",
    "\n",
    "plt.plot(X_test[0], label = \"original\")\n",
    "plt.plot(X_adversarial_fgsm.numpy()[0], label = \"pertubated\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4dc88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "alpha = 0.025\n",
    "epsilon = 0.025\n",
    "X_adversarial_pgd = pgd_attack(X_test, y_test, model, iterations, alpha, epsilon, np.inf, clip_min = 0, clip_max = 100)\n",
    "\n",
    "pred = model.predict(X_adversarial_pgd)\n",
    "pred = scaler.inverse_transform(pred).reshape(1,-1)[0]\n",
    "y_test_inv = scaler.inverse_transform(y_test).reshape(1,-1)[0]\n",
    "\n",
    "print(\"MAE :\", np.mean(abs(y_test_inv - pred)))\n",
    "print(\"RMSE :\", RMSE(y_test_inv,pred))\n",
    "print(\"MSE :\", MSE(y_test_inv,pred))\n",
    "print(\"MAPE :\", MAPE(y_test_inv[y_test_inv >= 10],pred[y_test_inv >= 10]))\n",
    "print(\"SMAPE :\", SMAPE(y_test_inv,pred))\n",
    "print(\"R2 :\", r2_score(y_test_inv,pred))\n",
    "\n",
    "plt.plot(X_test[0], label = \"original\")\n",
    "plt.plot(X_adversarial_pgd.numpy()[0], label = \"pertubated\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fad185",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_test[0], label = \"original\")\n",
    "plt.plot(X_adversarial_fgsm.numpy()[0], label = \"FGSM\")\n",
    "plt.plot(X_adversarial_pgd.numpy()[0], label = \"PGD\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172a4ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(X_test[0]-X_adversarial_fgsm.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18d2b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(X_test[0]-X_adversarial_pgd.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae5d16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(X_test[0]-X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b827472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae2cb41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6486eef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ac7c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = tf.convert_to_tensor(X_test, dtype = tf.float32)\n",
    "imgv = tf.Variable(inp)\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(imgv)\n",
    "    predictions = model(imgv)\n",
    "    loss = tf.keras.losses.MeanSquaredError()(y_test, predictions)\n",
    "    grads = tape.gradient(loss,imgv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc8a70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "# make a plot\n",
    "ax1 = ax\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "scaled_grad = (grads[0].numpy() - np.amin(grads[0].numpy())) / (np.amax(grads[0].numpy()) - np.amin(grads[0].numpy()))\n",
    "\n",
    "# ax.plot(X_test[0], label = \"original\", color=\"red\")\n",
    "ax2.plot(tf.sign(grads[0]).numpy(), label = \"signed\", color=\"orange\")\n",
    "ax.plot(tf.sign(grads[0]).numpy()*scaled_grad, label = \"signed\", color=\"green\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ad6854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6614e8fb",
   "metadata": {},
   "source": [
    "# Cleverhans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e846c8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleverhans.tf2.attacks.fast_gradient_method import fast_gradient_method\n",
    "from cleverhans.tf2.attacks.projected_gradient_descent import projected_gradient_descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b9a881",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_adversarial_fgsm = fast_gradient_method(model, X_test, 0.1, 1)\n",
    "\n",
    "pred = model.predict(X_adversarial_fgsm)\n",
    "pred = scaler.inverse_transform(pred).reshape(1,-1)[0]\n",
    "y_test_inv = scaler.inverse_transform(y_test).reshape(1,-1)[0]\n",
    "\n",
    "print(\"MAE :\", np.mean(abs(y_test_inv - pred)))\n",
    "print(\"RMSE :\", RMSE(y_test_inv,pred))\n",
    "print(\"MSE :\", MSE(y_test_inv,pred))\n",
    "print(\"MAPE :\", MAPE(y_test_inv[y_test_inv >= 10],pred[y_test_inv >= 10]))\n",
    "print(\"SMAPE :\", SMAPE(y_test_inv,pred))\n",
    "print(\"R2 :\", r2_score(y_test_inv,pred))\n",
    "\n",
    "plt.plot(X_test[0], label = \"original\")\n",
    "plt.plot(X_adversarial_fgsm.numpy()[0], label = \"pertubated\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133a654f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
